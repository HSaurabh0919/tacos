{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "rnn_sentiment_analysis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOUKk9SUbbQWmN2cuX3OUUN"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "xjYXPuo87ptx"
      },
      "outputs": [],
      "source": [
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocabulary_size = 5000\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words = vocabulary_size)\n",
        "print('Loaded dataset with {} training samples, {} test samples'.format(len(X_train), len(X_test)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7bqeOfq7vsL",
        "outputId": "a21190c9-6b7b-4f32-a824-58859b06b5f0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 0s 0us/step\n",
            "17473536/17464789 [==============================] - 0s 0us/step\n",
            "Loaded dataset with 25000 training samples, 25000 test samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "word2id = imdb.get_word_index()\n",
        "id2word = {i: word for word, i in word2id.items()}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OgUhwz4f73O3",
        "outputId": "6697f526-d80a-43aa-e354-656c0cd7702b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "1646592/1641221 [==============================] - 0s 0us/step\n",
            "1654784/1641221 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('---review with words---')\n",
        "print([id2word.get(i, ' ') for i in X_train[10]])\n",
        "print('---label---')\n",
        "print(y_train[10])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OMkwaA1t8L96",
        "outputId": "8e272686-8d80-43a8-d492-a8a62cc1f693"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---review with words---\n",
            "['the', 'clear', 'fact', 'entertaining', 'there', 'life', 'back', 'br', 'is', 'and', 'show', 'of', 'performance', 'stars', 'br', 'actors', 'film', 'him', 'many', 'should', 'movie', 'reasons', 'to', 'and', 'reading', 'and', 'are', 'in', 'of', 'scenes', 'and', 'and', 'of', 'and', 'out', 'compared', 'not', 'boss', 'yes', 'to', 'and', 'show', 'its', 'disappointed', 'fact', 'raw', 'to', 'it', 'justice', 'by', 'br', 'of', 'where', 'clear', 'fact', 'many', 'your', 'way', 'and', 'with', 'city', 'nice', 'are', 'is', 'along', 'wrong', 'not', 'as', 'it', 'way', 'she', 'but', 'this', 'anything', 'up', \"haven't\", 'been', 'by', 'who', 'of', 'choices', 'br', 'of', 'you', 'to', 'as', 'this', \"i'd\", 'it', 'and', 'who', 'of', 'shot', \"you'll\", 'to', 'love', 'for', 'and', 'of', 'you', 'it', 'is', 'sequels', 'of', 'little', 'quest', 'are', 'seen', 'watched', 'front', 'chemistry', 'to', 'simply', 'alive', 'of', 'chris', 'being', 'it', 'is', 'say', 'easy', 'and', 'cry', 'in', 'chemistry', 'but', 'and', 'all', 'it', 'maybe', 'this', 'is', 'wing', 'film', 'job', 'live', 'of', 'and', 'relief', 'and', 'level', 'names', 'and', 'and', 'to', 'be', 'stops', 'serial', 'and', 'watch', 'is', 'men', 'go', 'this', 'of', 'wing', 'american', 'from', 'and', 'moving', 'is', 'accepted', 'put', 'this', 'of', 'jerry', 'for', 'places', 'so', 'work', 'and', 'watch', 'and', 'lot', 'br', 'that', 'from', 'sometimes', 'wondered', 'make', 'department', 'introduced', 'to', 'wondered', 'from', 'action', 'at', 'turns', 'in', 'low', 'that', 'in', 'gay', \"i'm\", 'of', 'chemistry', 'bible', 'i', 'i', 'simply', 'alive', 'it', 'is', 'time', 'done', 'inspector', 'to', 'watching', 'look', 'world', 'named', 'for', 'more', 'tells', 'up', 'many', 'fans', 'are', 'that', 'movie', 'music', 'her', 'get', 'grasp', 'but', 'seems', 'in', 'people', 'film', 'that', 'if', 'explain', 'in', 'why', 'for', 'and', 'find', 'of', 'where', 'br', 'if', 'and', 'movie', 'throughout', 'if', 'and', 'of', 'you', 'best', 'look', 'red', 'and', 'to', 'recently', 'in', 'successfully', 'much', 'unfortunately', 'going', 'dan', 'and', 'stuck', 'is', 'him', 'sequences', 'but', 'of', 'you', 'of', 'enough', 'for', 'its', 'br', 'that', 'beautiful', 'put', 'reasons', 'of', 'chris', 'chemistry', 'wing', 'and', 'for', 'of', 'you', 'red', 'time', 'and', 'to', 'as', 'companion', 'and', 'of', 'chris', 'less', 'br', 'of', 'subplots', 'torture', 'in', 'low', 'alive', 'in', 'gay', 'some', 'br', 'of', 'wing', 'if', 'time', 'actual', 'in', 'also', 'side', 'any', 'if', 'name', 'takes', 'for', 'of', 'friendship', 'it', 'of', '10', 'for', 'had', 'and', 'great', 'to', 'as', 'you', 'students', 'for', 'movie', 'of', 'going', 'and', 'for', 'bad', 'well', 'best', 'had', 'at', 'woman', 'br', 'musical', 'when', 'it', 'caused', 'of', 'gripping', 'to', 'as', 'gem', 'in', 'and', 'for', 'and', 'look', 'end', 'gene', 'in', 'at', 'world', 'aliens', 'of', 'you', 'it', 'meet', 'but', 'is', 'quite', 'br', 'western', 'ideas', 'of', 'chris', 'little', 'of', 'films', 'he', 'an', 'time', 'done', 'this', 'were', 'right', 'too', 'to', 'of', 'enough', 'for', 'of', 'ending', 'become', 'family', 'beautiful', 'are', 'make', 'right', 'being', 'it', 'time', 'much', 'bit', 'especially', 'craig', 'for', 'of', 'you', 'parts', 'bond', 'who', 'of', 'here', 'parts', 'at', 'due', 'given', 'movie', 'of', 'once', 'give', 'find', 'actor', 'to', 'recently', 'in', 'at', 'world', 'dolls', 'loved', 'and', 'it', 'is', 'video', 'him', 'fact', 'you', 'to', 'by', 'br', 'of', 'where', 'br', 'of', 'grown', 'fight', 'culture', 'leads']\n",
            "---label---\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Maximum review length: {}'.format(\n",
        "len(max((X_train + X_test), key=len))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xn2-RePj8O5u",
        "outputId": "3f20f340-a3c3-4277-e99f-236b0c28385a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Maximum review length: 2697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Minimum review length: {}'.format(\n",
        "len(min((X_test + X_test), key=len))))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "338o1A6K8YEc",
        "outputId": "08bf4da9-242d-4d19-d528-4903c0231c1e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Minimum review length: 14\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Pad Sequences\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "max_words = 500\n",
        "X_train = sequence.pad_sequences(X_train, maxlen=max_words)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=max_words)"
      ],
      "metadata": {
        "id": "OdO6f_lF8Zbi"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Basic model taken from here\n",
        "#https://github.com/susanli2016/NLP-with-Python/blob/master/Sentiment%20Analysis%20with%20RNN.ipynb \n",
        "from keras import Sequential\n",
        "from keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "\n",
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U9lmlfjf8cxB",
        "outputId": "15aa4170-fe0c-4962-97c8-20d83e36beda"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " lstm_3 (LSTM)               (None, 100)               53200     \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 213,301\n",
            "Trainable params: 213,301\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "0zKLXUIv8zqC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QI0pmqspaSKI",
        "outputId": "946df1ce-5073-4483-bb9f-12e8f85bc192"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 124s 312ms/step - loss: 0.4875 - accuracy: 0.7574 - val_loss: 0.3936 - val_accuracy: 0.8281\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 120s 308ms/step - loss: 0.3164 - accuracy: 0.8708 - val_loss: 0.2652 - val_accuracy: 0.8750\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 128s 327ms/step - loss: 0.2490 - accuracy: 0.9031 - val_loss: 0.2408 - val_accuracy: 0.9219\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb279d0edd0>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "id": "GY7x18mAaUJp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Try some other Stacked variants"
      ],
      "metadata": {
        "id": "Ud479WNfa0PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedding_size=32\n",
        "model=Sequential()\n",
        "model.add(Embedding(vocabulary_size, embedding_size, input_length=max_words))#input_dim,out_dim,input_length\n",
        "model.add(LSTM(100,return_sequences=True,input_shape=(embedding_size,max_words)))\n",
        "model.add(Dropout(0.1))\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zL0rp_Lsa3KP",
        "outputId": "b018a485-81d7-4d3e-8f81-562368792fa4"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_5 (Embedding)     (None, 500, 32)           160000    \n",
            "                                                                 \n",
            " lstm_6 (LSTM)               (None, 500, 100)          53200     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 500, 100)          0         \n",
            "                                                                 \n",
            " lstm_7 (LSTM)               (None, 100)               80400     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 101       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 293,701\n",
            "Trainable params: 293,701\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss='binary_crossentropy', \n",
        "             optimizer='adam', \n",
        "             metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "ZXk3-6DwcUBk"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "X_valid, y_valid = X_train[:batch_size], y_train[:batch_size]\n",
        "X_train2, y_train2 = X_train[batch_size:], y_train[batch_size:]\n",
        "\n",
        "model.fit(X_train2, y_train2, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=num_epochs)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jxYaXcTScwql",
        "outputId": "7d5bf559-70d8-47e1-e2cc-5800e685c54d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "390/390 [==============================] - 268s 681ms/step - loss: 0.4432 - accuracy: 0.7905 - val_loss: 0.3108 - val_accuracy: 0.8906\n",
            "Epoch 2/3\n",
            "390/390 [==============================] - 259s 664ms/step - loss: 0.2872 - accuracy: 0.8865 - val_loss: 0.3103 - val_accuracy: 0.8594\n",
            "Epoch 3/3\n",
            "390/390 [==============================] - 260s 667ms/step - loss: 0.2700 - accuracy: 0.8927 - val_loss: 0.1891 - val_accuracy: 0.9375\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fb27b4d9990>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scores = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', scores[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-4jK6PxGcy1p",
        "outputId": "a4090951-1cae-4338-fe05-ee4ed4be535a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.8721200227737427\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "wZyLz6r9f3ox"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}