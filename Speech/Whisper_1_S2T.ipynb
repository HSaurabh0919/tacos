{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBKaQvqfjlQO0G3l+a/BUb"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Speech to Text"
      ],
      "metadata": {
        "id": "NqfCkZMhsa48"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZMsKY_npr6u",
        "outputId": "b84f1846-d2ff-4170-b64b-e8eb2f8e1184"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytube\n",
            "  Downloading pytube-12.1.2-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.0/57.0 KB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pytube\n",
            "Successfully installed pytube-12.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install pytube"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Importing Pytube library\n",
        "import pytube\n",
        "\n",
        "# Reading the YouTube link\n",
        "video = \"https://www.youtube.com/watch?v=WrD02VBXpEg\"\n",
        "data = pytube.YouTube(video)\n",
        "\n",
        "# Converting and downloading as 'MP4' file\n",
        "audio = data.streams.get_audio_only()\n",
        "audio.download()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kC60J0Pqpuoy",
        "outputId": "0cfa845d-8f44-41ae-df28-0c9a69b672bc"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/Applying to tech jobs in 2023 be like.mp4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/openai/whisper.git -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ifJNUzd8p0VX",
        "outputId": "b4a09fcb-f4c2-40c1-a56f-78753b1f9f08"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m60.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m69.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/190.3 KB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for openai-whisper (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "###Import the whisper module\n",
        "import whisper"
      ],
      "metadata": {
        "id": "htq2pILJp0YZ"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = whisper.load_model(\"base\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FYzZb8Txp-DT",
        "outputId": "06ee6365-04b9-4012-fddb-62a1e45d6fbc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|███████████████████████████████████████| 139M/139M [00:02<00:00, 52.9MiB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = model.transcribe(\"Applying to tech jobs in 2023 be like.mp4\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1YreeGqLqRV-",
        "outputId": "ecbb9eb1-58a9-4632-bb44-ec84371b6388"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/whisper/transcribe.py:79: UserWarning: FP16 is not supported on CPU; using FP32 instead\n",
            "  warnings.warn(\"FP16 is not supported on CPU; using FP32 instead\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#printing the transcribe\n",
        "text['text']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "Ydt2VC4Jp-GC",
        "outputId": "629db0c2-5158-4ed0-d0ed-b152509c944a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\" This video is brought to you by Squarespace. Google's parent company Alphabet announcing today it will cut 12,000 positions. What can I say when Salesforce lays off 8,000 people or 10% of its debt? What can I say when I say this? What can I say when I say this? What can I say when I say this? All right, so you've been doing good in your interviews so far. Just one last question then you're done. I see you use GraphQL on your first internship three years ago. I'm sure you remember it, right? Please write me a query on how to mutate the load balancer so that it points to a different react component. I'm not sure if that's possible. All right, so I guess we're at the end of the interview now. You've erased everything so far. You did great except the last question. Don't worry about it. So you hear back from us soon for the next steps. I gotta go to my next meeting now so yeah, have a good day. I wish you the best. Goodbye. Okay. Wow, I guess I did good. I solved all the questions. I'm pretty sure I'm pretty sure I'm not. Like there's no way. Thank you for your time interviewing with us. Unfortunately, we've decided to move on with a different kind of... What the f***? Hey, Pan. What are you doing? I'm just chilling. What's up? I have a new app idea. I already made the landing page. Oh, wait, this looks pretty nice. What'd you make this with? Squarespace. You mean the one that gives people an online platform that lets people build websites easily? Yeah. The one that allows you to connect with your audience and generate revenue through gated members' only content and leverage audience insights all in one platform? Yeah. You can also display posts from your social profiles and automatically keep them updated. Mr. frying pan, so anything you'd like to say to your fans? Yes, please go to squarespace.com when you're ready to launch, use my link squarespace.com slash frying pan for 10% off your first purchase of your website. Okay, so what's the actual app idea? Ask Zinn, I don't know.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "language = 'hi'\n",
        "options = dict(language=language, beam_size=5, best_of=5)\n",
        "transcribe_options = dict(task=\"transcribe\", **options)\n",
        "translate_options = dict(task=\"translate\", **options)"
      ],
      "metadata": {
        "id": "ks52ofbNwa1H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "REFERENCE : https://lablab.ai/t/whisper-transcribe-youtube-video"
      ],
      "metadata": {
        "id": "0vgh6d7EqHqU"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2dMQ3iDfqJxj"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}